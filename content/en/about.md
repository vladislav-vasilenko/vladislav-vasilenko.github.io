Experienced ML/DL engineer focused on generative models: Diffusion, Flow-Matching, DiT. Worked with SDXL and Flux architectures, experimented with ControlNet and IP-Adapter.

Actively experimenting with LLMs hands-on: built an autograd engine and GPT-style Transformer decoder from scratch, studied attention internals, gradient stability, and ablation analysis. Currently deep-diving into LLM compression â€” from nanoGPT to Llama 3 scale.

Passionate about creating unique products that bring high-end technologies into industry and daily life.
