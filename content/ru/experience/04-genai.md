- Исследование Bark-подобного **AR-Transformer** (EnCodec) и StableAudio-подобной латентной диффузии (**DiT** на EnCodec); VAE + RVQ/VQ квантизаторы для латентных представлений звука.
- Исследование блоков из `stable-audio-tools`: dit.py / encodec.py / conditioners.py. Сравнение DiT-блоков с backbone-архитектурой **SDXL** (UNet) и **Flux** (DiT).
- Определение оптимальных слоёв для **LoRA-адаптации** и параметров глубины/ширины для оптимума качество/ресурсы.
- Применение **PEFT (LoRA/QLoRA)** для быстрой адаптации под домен/голос/жанр; обучение LoRA с LoRAW для DiT, абляции по rank/регуляризации/отбору данных.
- Оценка качества: **FAD**, **CLAPScore** и FID/CLIPScore/FVD (CV).
- Построение воспроизводимых ML-пайплайнов от подготовки данных до батчевого инференса. Логирование экспериментов в **W&B**.
- Оптимизация инференса: **xFormers/Flash-Attention**, шедулеры для диффузии, демо в Gradio.
- MLOps: **Docker + CI/CD**, мониторинг, экспорты в ONNX и Triton для прод-выкатки.
